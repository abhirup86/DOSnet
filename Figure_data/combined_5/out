35938
[6975, 5342, 23621]
float32
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

readenergyb_test3_all2p_backup4_backup3_branch.py:190: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("de...)`
  model=Model(input=[input1, input2, input3, input4], output=out)
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_3 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
model_1 (Model)                 (None, 4, 150)       155200      input_3[0][0]
                                                                 input_4[0][0]
                                                                 input_5[0][0]
__________________________________________________________________________________________________
model_3 (Model)                 (None, 4, 150)       155200      input_6[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 4, 600)       0           model_1[1][0]
                                                                 model_1[2][0]
                                                                 model_1[3][0]
                                                                 model_3[1][0]
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2400)         0           concatenate_4[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2400)         0           flatten_1[0][0]
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 200)          480200      dropout_1[0][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1000)         201000      dense_1[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1000)         1001000     dense_2[0][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            1001        dense_3[0][0]
==================================================================================================
Total params: 1,993,601
Trainable params: 1,993,401
Non-trainable params: 200
__________________________________________________________________________________________________
2020-06-15 15:03:57.992801: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Train on 1796 samples, validate on 34142 samples
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:198: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Epoch 1/60
1796/1796 [==============================] - 25s 14ms/step - loss: 0.4941 - mean_absolute_error: 0.9150 - val_loss: 0.6432 - val_mean_absolute_error: 1.1152
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

Epoch 2/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.2872 - mean_absolute_error: 0.6601 - val_loss: 0.5464 - val_mean_absolute_error: 0.9943
Epoch 3/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.2158 - mean_absolute_error: 0.5495 - val_loss: 0.4093 - val_mean_absolute_error: 0.8270
Epoch 4/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.1709 - mean_absolute_error: 0.4777 - val_loss: 0.3539 - val_mean_absolute_error: 0.7610
Epoch 5/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.1448 - mean_absolute_error: 0.4390 - val_loss: 0.2730 - val_mean_absolute_error: 0.6559
Epoch 6/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.1256 - mean_absolute_error: 0.4004 - val_loss: 0.1523 - val_mean_absolute_error: 0.4630
Epoch 7/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.1241 - mean_absolute_error: 0.3992 - val_loss: 0.1168 - val_mean_absolute_error: 0.3978
Epoch 8/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.1282 - mean_absolute_error: 0.4036 - val_loss: 0.1264 - val_mean_absolute_error: 0.4068
Epoch 9/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.1199 - mean_absolute_error: 0.3929 - val_loss: 0.1143 - val_mean_absolute_error: 0.3769
Epoch 10/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0990 - mean_absolute_error: 0.3533 - val_loss: 0.1083 - val_mean_absolute_error: 0.3747
Epoch 11/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.1137 - mean_absolute_error: 0.3791 - val_loss: 0.1073 - val_mean_absolute_error: 0.3700
Epoch 12/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.1119 - mean_absolute_error: 0.3745 - val_loss: 0.0967 - val_mean_absolute_error: 0.3442
Epoch 13/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0920 - mean_absolute_error: 0.3360 - val_loss: 0.1097 - val_mean_absolute_error: 0.3726
Epoch 14/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0833 - mean_absolute_error: 0.3239 - val_loss: 0.0843 - val_mean_absolute_error: 0.3154
Epoch 15/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0867 - mean_absolute_error: 0.3243 - val_loss: 0.0918 - val_mean_absolute_error: 0.3339
Epoch 16/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0678 - mean_absolute_error: 0.2867 - val_loss: 0.0665 - val_mean_absolute_error: 0.2757
Epoch 17/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0583 - mean_absolute_error: 0.2621 - val_loss: 0.0643 - val_mean_absolute_error: 0.2699
Epoch 18/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0557 - mean_absolute_error: 0.2530 - val_loss: 0.0676 - val_mean_absolute_error: 0.2802
Epoch 19/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0525 - mean_absolute_error: 0.2506 - val_loss: 0.0673 - val_mean_absolute_error: 0.2757
Epoch 20/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0509 - mean_absolute_error: 0.2422 - val_loss: 0.0609 - val_mean_absolute_error: 0.2628
Epoch 21/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0489 - mean_absolute_error: 0.2404 - val_loss: 0.0705 - val_mean_absolute_error: 0.2846
Epoch 22/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0460 - mean_absolute_error: 0.2325 - val_loss: 0.0644 - val_mean_absolute_error: 0.2746
Epoch 23/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0432 - mean_absolute_error: 0.2263 - val_loss: 0.0949 - val_mean_absolute_error: 0.3383
Epoch 24/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0444 - mean_absolute_error: 0.2278 - val_loss: 0.0640 - val_mean_absolute_error: 0.2713
Epoch 25/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0467 - mean_absolute_error: 0.2340 - val_loss: 0.0738 - val_mean_absolute_error: 0.2938
Epoch 26/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0499 - mean_absolute_error: 0.2442 - val_loss: 0.0644 - val_mean_absolute_error: 0.2664
Epoch 27/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0424 - mean_absolute_error: 0.2238 - val_loss: 0.0567 - val_mean_absolute_error: 0.2564
Epoch 28/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0400 - mean_absolute_error: 0.2181 - val_loss: 0.0580 - val_mean_absolute_error: 0.2570
Epoch 29/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0404 - mean_absolute_error: 0.2182 - val_loss: 0.0612 - val_mean_absolute_error: 0.2683
Epoch 30/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0345 - mean_absolute_error: 0.2014 - val_loss: 0.0532 - val_mean_absolute_error: 0.2421
Epoch 31/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0344 - mean_absolute_error: 0.2014 - val_loss: 0.0591 - val_mean_absolute_error: 0.2600
Epoch 32/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0357 - mean_absolute_error: 0.2048 - val_loss: 0.0706 - val_mean_absolute_error: 0.2842
Epoch 33/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0461 - mean_absolute_error: 0.2319 - val_loss: 0.0662 - val_mean_absolute_error: 0.2830
Epoch 34/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0417 - mean_absolute_error: 0.2226 - val_loss: 0.0585 - val_mean_absolute_error: 0.2579
Epoch 35/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0332 - mean_absolute_error: 0.2003 - val_loss: 0.0622 - val_mean_absolute_error: 0.2659
Epoch 36/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0282 - mean_absolute_error: 0.1803 - val_loss: 0.0510 - val_mean_absolute_error: 0.2355
Epoch 37/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0236 - mean_absolute_error: 0.1655 - val_loss: 0.0504 - val_mean_absolute_error: 0.2348
Epoch 38/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0223 - mean_absolute_error: 0.1585 - val_loss: 0.0496 - val_mean_absolute_error: 0.2308
Epoch 39/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0224 - mean_absolute_error: 0.1601 - val_loss: 0.0500 - val_mean_absolute_error: 0.2324
Epoch 40/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0231 - mean_absolute_error: 0.1617 - val_loss: 0.0496 - val_mean_absolute_error: 0.2314
Epoch 41/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0216 - mean_absolute_error: 0.1577 - val_loss: 0.0510 - val_mean_absolute_error: 0.2343
Epoch 42/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0210 - mean_absolute_error: 0.1583 - val_loss: 0.0494 - val_mean_absolute_error: 0.2305
Epoch 43/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0196 - mean_absolute_error: 0.1507 - val_loss: 0.0511 - val_mean_absolute_error: 0.2350
Epoch 44/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0200 - mean_absolute_error: 0.1526 - val_loss: 0.0517 - val_mean_absolute_error: 0.2358
Epoch 45/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0192 - mean_absolute_error: 0.1481 - val_loss: 0.0491 - val_mean_absolute_error: 0.2302
Epoch 46/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0193 - mean_absolute_error: 0.1483 - val_loss: 0.0489 - val_mean_absolute_error: 0.2292
Epoch 47/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0177 - mean_absolute_error: 0.1412 - val_loss: 0.0492 - val_mean_absolute_error: 0.2292
Epoch 48/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0184 - mean_absolute_error: 0.1446 - val_loss: 0.0490 - val_mean_absolute_error: 0.2288
Epoch 49/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0178 - mean_absolute_error: 0.1404 - val_loss: 0.0493 - val_mean_absolute_error: 0.2296
Epoch 50/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0181 - mean_absolute_error: 0.1436 - val_loss: 0.0489 - val_mean_absolute_error: 0.2291
Epoch 51/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0172 - mean_absolute_error: 0.1410 - val_loss: 0.0486 - val_mean_absolute_error: 0.2281
Epoch 52/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0171 - mean_absolute_error: 0.1406 - val_loss: 0.0487 - val_mean_absolute_error: 0.2287
Epoch 53/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0174 - mean_absolute_error: 0.1429 - val_loss: 0.0492 - val_mean_absolute_error: 0.2294
Epoch 54/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0177 - mean_absolute_error: 0.1446 - val_loss: 0.0489 - val_mean_absolute_error: 0.2293
Epoch 55/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0170 - mean_absolute_error: 0.1383 - val_loss: 0.0497 - val_mean_absolute_error: 0.2302
Epoch 56/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0163 - mean_absolute_error: 0.1369 - val_loss: 0.0489 - val_mean_absolute_error: 0.2284
Epoch 57/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0165 - mean_absolute_error: 0.1363 - val_loss: 0.0485 - val_mean_absolute_error: 0.2272
Epoch 58/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0162 - mean_absolute_error: 0.1359 - val_loss: 0.0488 - val_mean_absolute_error: 0.2277
Epoch 59/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0164 - mean_absolute_error: 0.1345 - val_loss: 0.0483 - val_mean_absolute_error: 0.2268
Epoch 60/60
1796/1796 [==============================] - 24s 13ms/step - loss: 0.0147 - mean_absolute_error: 0.1290 - val_loss: 0.0484 - val_mean_absolute_error: 0.2268
 train MAE:  0.09902699
 train RMSE:  0.13959988503630708
 test MAE:  0.22682326
 test RMSE:  0.32952552450387346
