37247
['index: ', 4, 'filename: ', '1_screen/4/DOS9', 'reaction: ', '0.5H2(g) + * -> H*', 'site: ', '{"H": "bridge|A_A|B"}', 'surface: ', ['Pt', 'Pt', 'Pt', 'Ti', 'Pt', 'Pt', 'Pt', 'Ti', 'Pt', 'Pt', 'Pt', 'Ti']]
35938
[6975, 5342, 23621]
float32
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

/global/cscratch1/sd/vfung/1_screen_copy/readenergyb_test3_all2p_backup4_backup3_branch.py:190: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("de...)`
  model=Model(input=[input1, input2, input3, input4], output=out)
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_3 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
model_1 (Model)                 (None, 4, 150)       155200      input_3[0][0]
                                                                 input_4[0][0]
                                                                 input_5[0][0]
__________________________________________________________________________________________________
model_3 (Model)                 (None, 4, 150)       155200      input_6[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 4, 600)       0           model_1[1][0]
                                                                 model_1[2][0]
                                                                 model_1[3][0]
                                                                 model_3[1][0]
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2400)         0           concatenate_4[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2400)         0           flatten_1[0][0]
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 200)          480200      dropout_1[0][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1000)         201000      dense_1[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1000)         1001000     dense_2[0][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            1001        dense_3[0][0]
==================================================================================================
Total params: 1,993,601
Trainable params: 1,993,401
Non-trainable params: 200
__________________________________________________________________________________________________
2020-06-15 07:15:28.057040: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Train on 10781 samples, validate on 25157 samples
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:198: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Epoch 1/60
10781/10781 [==============================] - 30s 3ms/step - loss: 0.2379 - mean_absolute_error: 0.5724 - val_loss: 0.1608 - val_mean_absolute_error: 0.4652
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

Epoch 2/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.1192 - mean_absolute_error: 0.3887 - val_loss: 0.0792 - val_mean_absolute_error: 0.3131
Epoch 3/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0951 - mean_absolute_error: 0.3435 - val_loss: 0.1207 - val_mean_absolute_error: 0.3785
Epoch 4/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0863 - mean_absolute_error: 0.3224 - val_loss: 0.0629 - val_mean_absolute_error: 0.2705
Epoch 5/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0703 - mean_absolute_error: 0.2911 - val_loss: 0.0600 - val_mean_absolute_error: 0.2664
Epoch 6/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0669 - mean_absolute_error: 0.2839 - val_loss: 0.0517 - val_mean_absolute_error: 0.2473
Epoch 7/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0617 - mean_absolute_error: 0.2714 - val_loss: 0.0561 - val_mean_absolute_error: 0.2531
Epoch 8/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0578 - mean_absolute_error: 0.2623 - val_loss: 0.0511 - val_mean_absolute_error: 0.2449
Epoch 9/60
10781/10781 [==============================] - 28s 3ms/step - loss: 0.0574 - mean_absolute_error: 0.2609 - val_loss: 0.0493 - val_mean_absolute_error: 0.2385
Epoch 10/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0543 - mean_absolute_error: 0.2521 - val_loss: 0.0474 - val_mean_absolute_error: 0.2401
Epoch 11/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0517 - mean_absolute_error: 0.2468 - val_loss: 0.0431 - val_mean_absolute_error: 0.2205
Epoch 12/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0498 - mean_absolute_error: 0.2428 - val_loss: 0.0458 - val_mean_absolute_error: 0.2347
Epoch 13/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0479 - mean_absolute_error: 0.2377 - val_loss: 0.0457 - val_mean_absolute_error: 0.2282
Epoch 14/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0445 - mean_absolute_error: 0.2281 - val_loss: 0.0398 - val_mean_absolute_error: 0.2152
Epoch 15/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0436 - mean_absolute_error: 0.2260 - val_loss: 0.0412 - val_mean_absolute_error: 0.2199
Epoch 16/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0312 - mean_absolute_error: 0.1883 - val_loss: 0.0329 - val_mean_absolute_error: 0.1901
Epoch 17/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0282 - mean_absolute_error: 0.1790 - val_loss: 0.0322 - val_mean_absolute_error: 0.1866
Epoch 18/60
10781/10781 [==============================] - 28s 3ms/step - loss: 0.0280 - mean_absolute_error: 0.1793 - val_loss: 0.0312 - val_mean_absolute_error: 0.1834
Epoch 19/60
10781/10781 [==============================] - 28s 3ms/step - loss: 0.0275 - mean_absolute_error: 0.1769 - val_loss: 0.0317 - val_mean_absolute_error: 0.1892
Epoch 20/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0264 - mean_absolute_error: 0.1737 - val_loss: 0.0306 - val_mean_absolute_error: 0.1817
Epoch 21/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0260 - mean_absolute_error: 0.1721 - val_loss: 0.0370 - val_mean_absolute_error: 0.2077
Epoch 22/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0267 - mean_absolute_error: 0.1746 - val_loss: 0.0290 - val_mean_absolute_error: 0.1789
Epoch 23/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0240 - mean_absolute_error: 0.1658 - val_loss: 0.0304 - val_mean_absolute_error: 0.1826
Epoch 24/60
10781/10781 [==============================] - 28s 3ms/step - loss: 0.0250 - mean_absolute_error: 0.1694 - val_loss: 0.0278 - val_mean_absolute_error: 0.1724
Epoch 25/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0238 - mean_absolute_error: 0.1645 - val_loss: 0.0291 - val_mean_absolute_error: 0.1779
Epoch 26/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0237 - mean_absolute_error: 0.1646 - val_loss: 0.0296 - val_mean_absolute_error: 0.1797
Epoch 27/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0223 - mean_absolute_error: 0.1593 - val_loss: 0.0370 - val_mean_absolute_error: 0.2078
Epoch 28/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0230 - mean_absolute_error: 0.1626 - val_loss: 0.0290 - val_mean_absolute_error: 0.1783
Epoch 29/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0223 - mean_absolute_error: 0.1604 - val_loss: 0.0282 - val_mean_absolute_error: 0.1757
Epoch 30/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0221 - mean_absolute_error: 0.1587 - val_loss: 0.0291 - val_mean_absolute_error: 0.1796
Epoch 31/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0208 - mean_absolute_error: 0.1548 - val_loss: 0.0331 - val_mean_absolute_error: 0.1929
Epoch 32/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0206 - mean_absolute_error: 0.1536 - val_loss: 0.0270 - val_mean_absolute_error: 0.1704
Epoch 33/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0201 - mean_absolute_error: 0.1519 - val_loss: 0.0255 - val_mean_absolute_error: 0.1656
Epoch 34/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0196 - mean_absolute_error: 0.1498 - val_loss: 0.0277 - val_mean_absolute_error: 0.1718
Epoch 35/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0201 - mean_absolute_error: 0.1519 - val_loss: 0.0287 - val_mean_absolute_error: 0.1770
Epoch 36/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0136 - mean_absolute_error: 0.1234 - val_loss: 0.0226 - val_mean_absolute_error: 0.1529
Epoch 37/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0123 - mean_absolute_error: 0.1181 - val_loss: 0.0224 - val_mean_absolute_error: 0.1517
Epoch 38/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0120 - mean_absolute_error: 0.1162 - val_loss: 0.0223 - val_mean_absolute_error: 0.1511
Epoch 39/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0117 - mean_absolute_error: 0.1151 - val_loss: 0.0225 - val_mean_absolute_error: 0.1514
Epoch 40/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0113 - mean_absolute_error: 0.1133 - val_loss: 0.0225 - val_mean_absolute_error: 0.1518
Epoch 41/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0112 - mean_absolute_error: 0.1125 - val_loss: 0.0226 - val_mean_absolute_error: 0.1522
Epoch 42/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0111 - mean_absolute_error: 0.1118 - val_loss: 0.0219 - val_mean_absolute_error: 0.1493
Epoch 43/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0110 - mean_absolute_error: 0.1115 - val_loss: 0.0230 - val_mean_absolute_error: 0.1531
Epoch 44/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0109 - mean_absolute_error: 0.1116 - val_loss: 0.0230 - val_mean_absolute_error: 0.1532
Epoch 45/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0107 - mean_absolute_error: 0.1102 - val_loss: 0.0222 - val_mean_absolute_error: 0.1502
Epoch 46/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0097 - mean_absolute_error: 0.1053 - val_loss: 0.0220 - val_mean_absolute_error: 0.1494
Epoch 47/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0097 - mean_absolute_error: 0.1051 - val_loss: 0.0218 - val_mean_absolute_error: 0.1487
Epoch 48/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0095 - mean_absolute_error: 0.1042 - val_loss: 0.0220 - val_mean_absolute_error: 0.1491
Epoch 49/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0095 - mean_absolute_error: 0.1040 - val_loss: 0.0217 - val_mean_absolute_error: 0.1478
Epoch 50/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.1032 - val_loss: 0.0221 - val_mean_absolute_error: 0.1499
Epoch 51/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0092 - mean_absolute_error: 0.1024 - val_loss: 0.0220 - val_mean_absolute_error: 0.1493
Epoch 52/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0091 - mean_absolute_error: 0.1020 - val_loss: 0.0221 - val_mean_absolute_error: 0.1496
Epoch 53/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0091 - mean_absolute_error: 0.1018 - val_loss: 0.0219 - val_mean_absolute_error: 0.1489
Epoch 54/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0092 - mean_absolute_error: 0.1026 - val_loss: 0.0218 - val_mean_absolute_error: 0.1483
Epoch 55/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0089 - mean_absolute_error: 0.1013 - val_loss: 0.0218 - val_mean_absolute_error: 0.1484
Epoch 56/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0084 - mean_absolute_error: 0.0980 - val_loss: 0.0216 - val_mean_absolute_error: 0.1473
Epoch 57/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0084 - mean_absolute_error: 0.0972 - val_loss: 0.0216 - val_mean_absolute_error: 0.1472
Epoch 58/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0083 - mean_absolute_error: 0.0973 - val_loss: 0.0215 - val_mean_absolute_error: 0.1468
Epoch 59/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0085 - mean_absolute_error: 0.0980 - val_loss: 0.0216 - val_mean_absolute_error: 0.1472
Epoch 60/60
10781/10781 [==============================] - 29s 3ms/step - loss: 0.0082 - mean_absolute_error: 0.0965 - val_loss: 0.0216 - val_mean_absolute_error: 0.1470
 train MAE:  0.074269675
 train RMSE:  0.10295795526635151
 test MAE:  0.14696282
 test RMSE:  0.2140213919937129
