37247
['index: ', 4, 'filename: ', '1_screen/4/DOS9', 'reaction: ', '0.5H2(g) + * -> H*', 'site: ', '{"H": "bridge|A_A|B"}', 'surface: ', ['Pt', 'Pt', 'Pt', 'Ti', 'Pt', 'Pt', 'Pt', 'Ti', 'Pt', 'Pt', 'Pt', 'Ti']]
35938
[6975, 5342, 23621]
float32
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

/global/cscratch1/sd/vfung/1_screen_copy/readenergyb_test3_all2p_backup4_backup3_branch.py:190: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("de...)`
  model=Model(input=[input1, input2, input3, input4], output=out)
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_3 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
model_1 (Model)                 (None, 4, 150)       155200      input_3[0][0]
                                                                 input_4[0][0]
                                                                 input_5[0][0]
__________________________________________________________________________________________________
model_3 (Model)                 (None, 4, 150)       155200      input_6[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 4, 600)       0           model_1[1][0]
                                                                 model_1[2][0]
                                                                 model_1[3][0]
                                                                 model_3[1][0]
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2400)         0           concatenate_4[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2400)         0           flatten_1[0][0]
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 200)          480200      dropout_1[0][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1000)         201000      dense_1[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1000)         1001000     dense_2[0][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            1001        dense_3[0][0]
==================================================================================================
Total params: 1,993,601
Trainable params: 1,993,401
Non-trainable params: 200
__________________________________________________________________________________________________
2020-06-15 10:09:35.361781: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Train on 25156 samples, validate on 10782 samples
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:198: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Epoch 1/60
25156/25156 [==============================] - 27s 1ms/step - loss: 0.1866 - mean_absolute_error: 0.4836 - val_loss: 0.3360 - val_mean_absolute_error: 0.7429
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

Epoch 2/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0790 - mean_absolute_error: 0.3100 - val_loss: 0.1091 - val_mean_absolute_error: 0.3708
Epoch 3/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0610 - mean_absolute_error: 0.2686 - val_loss: 0.0486 - val_mean_absolute_error: 0.2382
Epoch 4/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0524 - mean_absolute_error: 0.2481 - val_loss: 0.0378 - val_mean_absolute_error: 0.2073
Epoch 5/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0487 - mean_absolute_error: 0.2389 - val_loss: 0.0494 - val_mean_absolute_error: 0.2385
Epoch 6/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0450 - mean_absolute_error: 0.2288 - val_loss: 0.0342 - val_mean_absolute_error: 0.1949
Epoch 7/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0394 - mean_absolute_error: 0.2135 - val_loss: 0.0341 - val_mean_absolute_error: 0.1987
Epoch 8/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0365 - mean_absolute_error: 0.2046 - val_loss: 0.0390 - val_mean_absolute_error: 0.2117
Epoch 9/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0351 - mean_absolute_error: 0.1995 - val_loss: 0.0286 - val_mean_absolute_error: 0.1801
Epoch 10/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0332 - mean_absolute_error: 0.1952 - val_loss: 0.0297 - val_mean_absolute_error: 0.1842
Epoch 11/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0323 - mean_absolute_error: 0.1922 - val_loss: 0.0271 - val_mean_absolute_error: 0.1734
Epoch 12/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0316 - mean_absolute_error: 0.1901 - val_loss: 0.0263 - val_mean_absolute_error: 0.1693
Epoch 13/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0315 - mean_absolute_error: 0.1900 - val_loss: 0.0289 - val_mean_absolute_error: 0.1795
Epoch 14/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0282 - mean_absolute_error: 0.1794 - val_loss: 0.0268 - val_mean_absolute_error: 0.1756
Epoch 15/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0289 - mean_absolute_error: 0.1812 - val_loss: 0.0317 - val_mean_absolute_error: 0.1890
Epoch 16/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0203 - mean_absolute_error: 0.1500 - val_loss: 0.0193 - val_mean_absolute_error: 0.1440
Epoch 17/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.1442 - val_loss: 0.0186 - val_mean_absolute_error: 0.1400
Epoch 18/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0190 - mean_absolute_error: 0.1455 - val_loss: 0.0183 - val_mean_absolute_error: 0.1382
Epoch 19/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0181 - mean_absolute_error: 0.1416 - val_loss: 0.0185 - val_mean_absolute_error: 0.1386
Epoch 20/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0177 - mean_absolute_error: 0.1403 - val_loss: 0.0198 - val_mean_absolute_error: 0.1473
Epoch 21/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0177 - mean_absolute_error: 0.1410 - val_loss: 0.0183 - val_mean_absolute_error: 0.1383
Epoch 22/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0173 - mean_absolute_error: 0.1383 - val_loss: 0.0189 - val_mean_absolute_error: 0.1412
Epoch 23/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0176 - mean_absolute_error: 0.1408 - val_loss: 0.0209 - val_mean_absolute_error: 0.1512
Epoch 24/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0172 - mean_absolute_error: 0.1382 - val_loss: 0.0204 - val_mean_absolute_error: 0.1489
Epoch 25/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0168 - mean_absolute_error: 0.1375 - val_loss: 0.0177 - val_mean_absolute_error: 0.1376
Epoch 26/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0177 - mean_absolute_error: 0.1413 - val_loss: 0.0195 - val_mean_absolute_error: 0.1463
Epoch 27/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0163 - mean_absolute_error: 0.1351 - val_loss: 0.0180 - val_mean_absolute_error: 0.1377
Epoch 28/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0162 - mean_absolute_error: 0.1347 - val_loss: 0.0185 - val_mean_absolute_error: 0.1407
Epoch 29/60
25156/25156 [==============================] - 25s 1ms/step - loss: 0.0164 - mean_absolute_error: 0.1356 - val_loss: 0.0190 - val_mean_absolute_error: 0.1446
Epoch 30/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0164 - mean_absolute_error: 0.1358 - val_loss: 0.0256 - val_mean_absolute_error: 0.1645
Epoch 31/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0168 - mean_absolute_error: 0.1371 - val_loss: 0.0176 - val_mean_absolute_error: 0.1358
Epoch 32/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0155 - mean_absolute_error: 0.1322 - val_loss: 0.0184 - val_mean_absolute_error: 0.1394
Epoch 33/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0156 - mean_absolute_error: 0.1321 - val_loss: 0.0185 - val_mean_absolute_error: 0.1390
Epoch 34/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0155 - mean_absolute_error: 0.1312 - val_loss: 0.0190 - val_mean_absolute_error: 0.1425
Epoch 35/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0149 - mean_absolute_error: 0.1291 - val_loss: 0.0172 - val_mean_absolute_error: 0.1354
Epoch 36/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0112 - mean_absolute_error: 0.1104 - val_loss: 0.0147 - val_mean_absolute_error: 0.1217
Epoch 37/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0104 - mean_absolute_error: 0.1066 - val_loss: 0.0144 - val_mean_absolute_error: 0.1200
Epoch 38/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0101 - mean_absolute_error: 0.1051 - val_loss: 0.0144 - val_mean_absolute_error: 0.1202
Epoch 39/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0099 - mean_absolute_error: 0.1040 - val_loss: 0.0142 - val_mean_absolute_error: 0.1189
Epoch 40/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0100 - mean_absolute_error: 0.1043 - val_loss: 0.0150 - val_mean_absolute_error: 0.1230
Epoch 41/60
25156/25156 [==============================] - 25s 1ms/step - loss: 0.0098 - mean_absolute_error: 0.1030 - val_loss: 0.0145 - val_mean_absolute_error: 0.1211
Epoch 42/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0097 - mean_absolute_error: 0.1024 - val_loss: 0.0142 - val_mean_absolute_error: 0.1193
Epoch 43/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0095 - mean_absolute_error: 0.1015 - val_loss: 0.0145 - val_mean_absolute_error: 0.1202
Epoch 44/60
25156/25156 [==============================] - 25s 1ms/step - loss: 0.0095 - mean_absolute_error: 0.1015 - val_loss: 0.0145 - val_mean_absolute_error: 0.1197
Epoch 45/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0095 - mean_absolute_error: 0.1016 - val_loss: 0.0143 - val_mean_absolute_error: 0.1186
Epoch 46/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0089 - mean_absolute_error: 0.0982 - val_loss: 0.0141 - val_mean_absolute_error: 0.1176
Epoch 47/60
25156/25156 [==============================] - 25s 1ms/step - loss: 0.0088 - mean_absolute_error: 0.0976 - val_loss: 0.0141 - val_mean_absolute_error: 0.1178
Epoch 48/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0088 - mean_absolute_error: 0.0971 - val_loss: 0.0139 - val_mean_absolute_error: 0.1167
Epoch 49/60
25156/25156 [==============================] - 25s 1ms/step - loss: 0.0088 - mean_absolute_error: 0.0975 - val_loss: 0.0140 - val_mean_absolute_error: 0.1172
Epoch 50/60
25156/25156 [==============================] - 25s 1ms/step - loss: 0.0088 - mean_absolute_error: 0.0971 - val_loss: 0.0140 - val_mean_absolute_error: 0.1173
Epoch 51/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0087 - mean_absolute_error: 0.0971 - val_loss: 0.0141 - val_mean_absolute_error: 0.1178
Epoch 52/60
25156/25156 [==============================] - 25s 1ms/step - loss: 0.0087 - mean_absolute_error: 0.0965 - val_loss: 0.0140 - val_mean_absolute_error: 0.1169
Epoch 53/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0086 - mean_absolute_error: 0.0963 - val_loss: 0.0141 - val_mean_absolute_error: 0.1173
Epoch 54/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0086 - mean_absolute_error: 0.0965 - val_loss: 0.0141 - val_mean_absolute_error: 0.1178
Epoch 55/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0085 - mean_absolute_error: 0.0962 - val_loss: 0.0141 - val_mean_absolute_error: 0.1174
Epoch 56/60
25156/25156 [==============================] - 25s 1ms/step - loss: 0.0081 - mean_absolute_error: 0.0935 - val_loss: 0.0139 - val_mean_absolute_error: 0.1159
Epoch 57/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0080 - mean_absolute_error: 0.0929 - val_loss: 0.0138 - val_mean_absolute_error: 0.1157
Epoch 58/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0080 - mean_absolute_error: 0.0928 - val_loss: 0.0138 - val_mean_absolute_error: 0.1157
Epoch 59/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0080 - mean_absolute_error: 0.0932 - val_loss: 0.0138 - val_mean_absolute_error: 0.1154
Epoch 60/60
25156/25156 [==============================] - 26s 1ms/step - loss: 0.0080 - mean_absolute_error: 0.0922 - val_loss: 0.0138 - val_mean_absolute_error: 0.1156
 train MAE:  0.07629675
 train RMSE:  0.11020803823623859
 test MAE:  0.11563066
 test RMSE:  0.17095040757299987
