Using TensorFlow backend.
2020-07-03 12:34:22.635348: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-03 12:34:22.645748: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300070000 Hz
2020-07-03 12:34:22.648992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2aacb0000b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-03 12:34:22.649007: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-03 12:34:22.655785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-03 12:34:22.659654: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-07-03 12:34:22.659685: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nid00030): /proc/driver/nvidia/version does not exist
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 10535220756428455330
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 14184010963477965344
physical_device_desc: "device: XLA_CPU device"
]
2020-07-03 12:35:45.443523: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.
readenergyb_test3_all2p_backup4_backup3_branch_production_transfer.py:116: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("de...)`
  model=Model(input=[input1, input2, input3, input4], output=out)
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_3 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
model_1 (Model)                 (None, 4, 150)       155200      input_3[0][0]
                                                                 input_4[0][0]
                                                                 input_5[0][0]
__________________________________________________________________________________________________
model_3 (Model)                 (None, 4, 150)       155200      input_6[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 4, 600)       0           model_1[1][0]
                                                                 model_1[2][0]
                                                                 model_1[3][0]
                                                                 model_3[1][0]
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2400)         0           concatenate_4[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2400)         0           flatten_1[0][0]
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 200)          480200      dropout_1[0][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1000)         201000      dense_1[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1000)         1001000     dense_2[0][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            1001        dense_3[0][0]
==================================================================================================
Total params: 1,993,601
Trainable params: 1,993,401
Non-trainable params: 200
__________________________________________________________________________________________________
Train on 30005 samples, validate on 5933 samples
Epoch 1/60
  256/30005 [..............................] - ETA: 2:24 - loss: 1.1853 - mean_absolute_error: 1.75152020-07-03 12:35:50.018700: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: logs/1593804945.4434488/train/plugins/profile/2020_07_03_12_35_50
2020-07-03 12:35:50.026269: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to logs/1593804945.4434488/train/plugins/profile/2020_07_03_12_35_50/nid00030.trace.json.gz
2020-07-03 12:35:50.031378: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.228 ms

2020-07-03 12:35:50.048320: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: logs/1593804945.4434488/train/plugins/profile/2020_07_03_12_35_50Dumped tool data for overview_page.pb to logs/1593804945.4434488/train/plugins/profile/2020_07_03_12_35_50/nid00030.overview_page.pb
Dumped tool data for input_pipeline.pb to logs/1593804945.4434488/train/plugins/profile/2020_07_03_12_35_50/nid00030.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to logs/1593804945.4434488/train/plugins/profile/2020_07_03_12_35_50/nid00030.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to logs/1593804945.4434488/train/plugins/profile/2020_07_03_12_35_50/nid00030.kernel_stats.pb
30005/30005 [==============================] - 28s 943us/step - loss: 0.1942 - mean_absolute_error: 0.4994 - val_loss: 0.0895 - val_mean_absolute_error: 0.3372
Epoch 2/60
30005/30005 [==============================] - 27s 889us/step - loss: 0.0767 - mean_absolute_error: 0.3118 - val_loss: 0.0256 - val_mean_absolute_error: 0.1595
Epoch 3/60
30005/30005 [==============================] - 26s 881us/step - loss: 0.0632 - mean_absolute_error: 0.2792 - val_loss: 0.0189 - val_mean_absolute_error: 0.1314
Epoch 4/60
30005/30005 [==============================] - 26s 882us/step - loss: 0.0508 - mean_absolute_error: 0.2491 - val_loss: 0.0197 - val_mean_absolute_error: 0.1408
Epoch 5/60
30005/30005 [==============================] - 26s 880us/step - loss: 0.0451 - mean_absolute_error: 0.2354 - val_loss: 0.0207 - val_mean_absolute_error: 0.1438
Epoch 6/60
30005/30005 [==============================] - 26s 875us/step - loss: 0.0414 - mean_absolute_error: 0.2231 - val_loss: 0.0183 - val_mean_absolute_error: 0.1327
Epoch 7/60
30005/30005 [==============================] - 26s 881us/step - loss: 0.0376 - mean_absolute_error: 0.2128 - val_loss: 0.0345 - val_mean_absolute_error: 0.2073
Epoch 8/60
30005/30005 [==============================] - 27s 887us/step - loss: 0.0365 - mean_absolute_error: 0.2087 - val_loss: 0.0337 - val_mean_absolute_error: 0.2051
Epoch 9/60
30005/30005 [==============================] - 27s 887us/step - loss: 0.0352 - mean_absolute_error: 0.2053 - val_loss: 0.0251 - val_mean_absolute_error: 0.1669
Epoch 10/60
30005/30005 [==============================] - 26s 882us/step - loss: 0.0313 - mean_absolute_error: 0.1930 - val_loss: 0.0166 - val_mean_absolute_error: 0.1288
Epoch 11/60
30005/30005 [==============================] - 27s 888us/step - loss: 0.0312 - mean_absolute_error: 0.1926 - val_loss: 0.0161 - val_mean_absolute_error: 0.1241
Epoch 12/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0292 - mean_absolute_error: 0.1862 - val_loss: 0.0170 - val_mean_absolute_error: 0.1322
Epoch 13/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0296 - mean_absolute_error: 0.1867 - val_loss: 0.0152 - val_mean_absolute_error: 0.1226
Epoch 14/60
30005/30005 [==============================] - 26s 880us/step - loss: 0.0294 - mean_absolute_error: 0.1878 - val_loss: 0.0141 - val_mean_absolute_error: 0.1122
Epoch 15/60
30005/30005 [==============================] - 27s 886us/step - loss: 0.0274 - mean_absolute_error: 0.1801 - val_loss: 0.0165 - val_mean_absolute_error: 0.1281
Epoch 16/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0200 - mean_absolute_error: 0.1515 - val_loss: 0.0133 - val_mean_absolute_error: 0.1116
Epoch 17/60
30005/30005 [==============================] - 26s 878us/step - loss: 0.0195 - mean_absolute_error: 0.1497 - val_loss: 0.0135 - val_mean_absolute_error: 0.1112
Epoch 18/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0189 - mean_absolute_error: 0.1478 - val_loss: 0.0129 - val_mean_absolute_error: 0.1104
Epoch 19/60
30005/30005 [==============================] - 27s 885us/step - loss: 0.0184 - mean_absolute_error: 0.1454 - val_loss: 0.0150 - val_mean_absolute_error: 0.1246
Epoch 20/60
30005/30005 [==============================] - 26s 883us/step - loss: 0.0189 - mean_absolute_error: 0.1478 - val_loss: 0.0125 - val_mean_absolute_error: 0.1088
Epoch 21/60
30005/30005 [==============================] - 27s 887us/step - loss: 0.0181 - mean_absolute_error: 0.1445 - val_loss: 0.0387 - val_mean_absolute_error: 0.2156
Epoch 22/60
30005/30005 [==============================] - 27s 890us/step - loss: 0.0182 - mean_absolute_error: 0.1448 - val_loss: 0.0123 - val_mean_absolute_error: 0.1084
Epoch 23/60
30005/30005 [==============================] - 27s 887us/step - loss: 0.0178 - mean_absolute_error: 0.1433 - val_loss: 0.0117 - val_mean_absolute_error: 0.1038
Epoch 24/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0184 - mean_absolute_error: 0.1457 - val_loss: 0.0130 - val_mean_absolute_error: 0.1137
Epoch 25/60
30005/30005 [==============================] - 27s 886us/step - loss: 0.0171 - mean_absolute_error: 0.1401 - val_loss: 0.0114 - val_mean_absolute_error: 0.1027
Epoch 26/60
30005/30005 [==============================] - 26s 882us/step - loss: 0.0174 - mean_absolute_error: 0.1421 - val_loss: 0.0117 - val_mean_absolute_error: 0.1080
Epoch 27/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0166 - mean_absolute_error: 0.1386 - val_loss: 0.0163 - val_mean_absolute_error: 0.1315
Epoch 28/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0170 - mean_absolute_error: 0.1403 - val_loss: 0.0118 - val_mean_absolute_error: 0.1079
Epoch 29/60
30005/30005 [==============================] - 26s 882us/step - loss: 0.0167 - mean_absolute_error: 0.1391 - val_loss: 0.0117 - val_mean_absolute_error: 0.1046
Epoch 30/60
30005/30005 [==============================] - 27s 886us/step - loss: 0.0167 - mean_absolute_error: 0.1396 - val_loss: 0.0134 - val_mean_absolute_error: 0.1148
Epoch 31/60
30005/30005 [==============================] - 26s 882us/step - loss: 0.0163 - mean_absolute_error: 0.1369 - val_loss: 0.0124 - val_mean_absolute_error: 0.1107
Epoch 32/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0160 - mean_absolute_error: 0.1360 - val_loss: 0.0132 - val_mean_absolute_error: 0.1147
Epoch 33/60
30005/30005 [==============================] - 26s 881us/step - loss: 0.0157 - mean_absolute_error: 0.1350 - val_loss: 0.0138 - val_mean_absolute_error: 0.1171
Epoch 34/60
30005/30005 [==============================] - 26s 879us/step - loss: 0.0154 - mean_absolute_error: 0.1337 - val_loss: 0.0112 - val_mean_absolute_error: 0.1040
Epoch 35/60
30005/30005 [==============================] - 26s 879us/step - loss: 0.0152 - mean_absolute_error: 0.1328 - val_loss: 0.0131 - val_mean_absolute_error: 0.1112
Epoch 36/60
30005/30005 [==============================] - 26s 883us/step - loss: 0.0113 - mean_absolute_error: 0.1126 - val_loss: 0.0109 - val_mean_absolute_error: 0.1008
Epoch 37/60
30005/30005 [==============================] - 26s 879us/step - loss: 0.0105 - mean_absolute_error: 0.1083 - val_loss: 0.0107 - val_mean_absolute_error: 0.0996
Epoch 38/60
30005/30005 [==============================] - 26s 882us/step - loss: 0.0104 - mean_absolute_error: 0.1074 - val_loss: 0.0106 - val_mean_absolute_error: 0.0995
Epoch 39/60
30005/30005 [==============================] - 27s 886us/step - loss: 0.0101 - mean_absolute_error: 0.1061 - val_loss: 0.0113 - val_mean_absolute_error: 0.1031
Epoch 40/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0100 - mean_absolute_error: 0.1058 - val_loss: 0.0109 - val_mean_absolute_error: 0.1005
Epoch 41/60
30005/30005 [==============================] - 27s 883us/step - loss: 0.0099 - mean_absolute_error: 0.1051 - val_loss: 0.0106 - val_mean_absolute_error: 0.0991
Epoch 42/60
30005/30005 [==============================] - 27s 887us/step - loss: 0.0099 - mean_absolute_error: 0.1053 - val_loss: 0.0109 - val_mean_absolute_error: 0.1003
Epoch 43/60
30005/30005 [==============================] - 27s 885us/step - loss: 0.0098 - mean_absolute_error: 0.1046 - val_loss: 0.0107 - val_mean_absolute_error: 0.1008
Epoch 44/60
30005/30005 [==============================] - 26s 881us/step - loss: 0.0097 - mean_absolute_error: 0.1038 - val_loss: 0.0125 - val_mean_absolute_error: 0.1082
Epoch 45/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0096 - mean_absolute_error: 0.1038 - val_loss: 0.0121 - val_mean_absolute_error: 0.1069
Epoch 46/60
30005/30005 [==============================] - 27s 890us/step - loss: 0.0091 - mean_absolute_error: 0.1004 - val_loss: 0.0110 - val_mean_absolute_error: 0.0997
Epoch 47/60
30005/30005 [==============================] - 26s 883us/step - loss: 0.0091 - mean_absolute_error: 0.1006 - val_loss: 0.0108 - val_mean_absolute_error: 0.0996
Epoch 48/60
30005/30005 [==============================] - 26s 883us/step - loss: 0.0089 - mean_absolute_error: 0.0992 - val_loss: 0.0107 - val_mean_absolute_error: 0.0991
Epoch 49/60
30005/30005 [==============================] - 26s 880us/step - loss: 0.0089 - mean_absolute_error: 0.0988 - val_loss: 0.0110 - val_mean_absolute_error: 0.1002
Epoch 50/60
30005/30005 [==============================] - 27s 888us/step - loss: 0.0088 - mean_absolute_error: 0.0988 - val_loss: 0.0111 - val_mean_absolute_error: 0.1007
Epoch 51/60
30005/30005 [==============================] - 27s 890us/step - loss: 0.0089 - mean_absolute_error: 0.0995 - val_loss: 0.0104 - val_mean_absolute_error: 0.0979
Epoch 52/60
30005/30005 [==============================] - 26s 883us/step - loss: 0.0088 - mean_absolute_error: 0.0985 - val_loss: 0.0110 - val_mean_absolute_error: 0.1001
Epoch 53/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0087 - mean_absolute_error: 0.0987 - val_loss: 0.0112 - val_mean_absolute_error: 0.1005
Epoch 54/60
30005/30005 [==============================] - 27s 888us/step - loss: 0.0088 - mean_absolute_error: 0.0984 - val_loss: 0.0110 - val_mean_absolute_error: 0.1016
Epoch 55/60
30005/30005 [==============================] - 27s 885us/step - loss: 0.0087 - mean_absolute_error: 0.0980 - val_loss: 0.0111 - val_mean_absolute_error: 0.1000
Epoch 56/60
30005/30005 [==============================] - 27s 884us/step - loss: 0.0082 - mean_absolute_error: 0.0951 - val_loss: 0.0109 - val_mean_absolute_error: 0.0992
Epoch 57/60
30005/30005 [==============================] - 27s 885us/step - loss: 0.0082 - mean_absolute_error: 0.0948 - val_loss: 0.0109 - val_mean_absolute_error: 0.0994
Epoch 58/60
30005/30005 [==============================] - 27s 890us/step - loss: 0.0082 - mean_absolute_error: 0.0947 - val_loss: 0.0110 - val_mean_absolute_error: 0.0995
Epoch 59/60
30005/30005 [==============================] - 27s 885us/step - loss: 0.0082 - mean_absolute_error: 0.0948 - val_loss: 0.0109 - val_mean_absolute_error: 0.0995
Epoch 60/60
30005/30005 [==============================] - 27s 886us/step - loss: 0.0081 - mean_absolute_error: 0.0946 - val_loss: 0.0109 - val_mean_absolute_error: 0.0996
train MAE:  0.08029968
train RMSE:  0.11400685912858799
test MAE:  0.09959772
test RMSE:  0.15270828380319365
