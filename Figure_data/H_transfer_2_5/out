 Using TensorFlow backend.
2020-07-03 13:37:34.543867: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-03 13:37:34.554422: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300070000 Hz
2020-07-03 13:37:34.557635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2aacb0000b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-03 13:37:34.557649: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-03 13:37:34.561039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-03 13:37:34.565178: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-07-03 13:37:34.565198: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nid00030): /proc/driver/nvidia/version does not exist
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 17727366870008429314
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 14456387034611204813
physical_device_desc: "device: XLA_CPU device"
]
2020-07-03 13:38:56.110847: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.
readenergyb_test3_all2p_backup4_backup3_branch_production_transfer.py:116: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("de...)`
  model=Model(input=[input1, input2, input3, input4], output=out)
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_3 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
model_1 (Model)                 (None, 4, 150)       155200      input_3[0][0]
                                                                 input_4[0][0]
                                                                 input_5[0][0]
__________________________________________________________________________________________________
model_3 (Model)                 (None, 4, 150)       155200      input_6[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 4, 600)       0           model_1[1][0]
                                                                 model_1[2][0]
                                                                 model_1[3][0]
                                                                 model_3[1][0]
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2400)         0           concatenate_4[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2400)         0           flatten_1[0][0]
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 200)          480200      dropout_1[0][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1000)         201000      dense_1[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1000)         1001000     dense_2[0][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            1001        dense_3[0][0]
==================================================================================================
Total params: 1,993,601
Trainable params: 1,993,401
Non-trainable params: 200
__________________________________________________________________________________________________
Train on 29510 samples, validate on 6428 samples
Epoch 1/60
  256/29510 [..............................] - ETA: 2:20 - loss: 1.1171 - mean_absolute_error: 1.66242020-07-03 13:39:00.762624: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: logs/1593808736.110765/train/plugins/profile/2020_07_03_13_39_00
2020-07-03 13:39:00.770376: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to logs/1593808736.110765/train/plugins/profile/2020_07_03_13_39_00/nid00030.trace.json.gz
2020-07-03 13:39:00.775529: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.253 ms

2020-07-03 13:39:00.790445: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: logs/1593808736.110765/train/plugins/profile/2020_07_03_13_39_00Dumped tool data for overview_page.pb to logs/1593808736.110765/train/plugins/profile/2020_07_03_13_39_00/nid00030.overview_page.pb
Dumped tool data for input_pipeline.pb to logs/1593808736.110765/train/plugins/profile/2020_07_03_13_39_00/nid00030.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to logs/1593808736.110765/train/plugins/profile/2020_07_03_13_39_00/nid00030.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to logs/1593808736.110765/train/plugins/profile/2020_07_03_13_39_00/nid00030.kernel_stats.pb
29510/29510 [==============================] - 28s 951us/step - loss: 0.1914 - mean_absolute_error: 0.4971 - val_loss: 0.0885 - val_mean_absolute_error: 0.3471
Epoch 2/60
29510/29510 [==============================] - 27s 899us/step - loss: 0.0758 - mean_absolute_error: 0.3098 - val_loss: 0.0419 - val_mean_absolute_error: 0.2274
Epoch 3/60
29510/29510 [==============================] - 27s 905us/step - loss: 0.0576 - mean_absolute_error: 0.2677 - val_loss: 0.0317 - val_mean_absolute_error: 0.1913
Epoch 4/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0515 - mean_absolute_error: 0.2515 - val_loss: 0.0285 - val_mean_absolute_error: 0.1795
Epoch 5/60
29510/29510 [==============================] - 27s 899us/step - loss: 0.0464 - mean_absolute_error: 0.2382 - val_loss: 0.0262 - val_mean_absolute_error: 0.1709
Epoch 6/60
29510/29510 [==============================] - 27s 904us/step - loss: 0.0434 - mean_absolute_error: 0.2297 - val_loss: 0.0204 - val_mean_absolute_error: 0.1473
Epoch 7/60
29510/29510 [==============================] - 27s 904us/step - loss: 0.0388 - mean_absolute_error: 0.2167 - val_loss: 0.0254 - val_mean_absolute_error: 0.1674
Epoch 8/60
29510/29510 [==============================] - 27s 905us/step - loss: 0.0354 - mean_absolute_error: 0.2062 - val_loss: 0.0231 - val_mean_absolute_error: 0.1572
Epoch 9/60
29510/29510 [==============================] - 27s 903us/step - loss: 0.0341 - mean_absolute_error: 0.2025 - val_loss: 0.0288 - val_mean_absolute_error: 0.1889
Epoch 10/60
29510/29510 [==============================] - 27s 901us/step - loss: 0.0321 - mean_absolute_error: 0.1959 - val_loss: 0.0202 - val_mean_absolute_error: 0.1451
Epoch 11/60
29510/29510 [==============================] - 27s 902us/step - loss: 0.0309 - mean_absolute_error: 0.1927 - val_loss: 0.0279 - val_mean_absolute_error: 0.1787
Epoch 12/60
29510/29510 [==============================] - 27s 904us/step - loss: 0.0292 - mean_absolute_error: 0.1868 - val_loss: 0.0187 - val_mean_absolute_error: 0.1394
Epoch 13/60
29510/29510 [==============================] - 27s 899us/step - loss: 0.0293 - mean_absolute_error: 0.1873 - val_loss: 0.0191 - val_mean_absolute_error: 0.1436
Epoch 14/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0281 - mean_absolute_error: 0.1827 - val_loss: 0.0238 - val_mean_absolute_error: 0.1685
Epoch 15/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0270 - mean_absolute_error: 0.1792 - val_loss: 0.0219 - val_mean_absolute_error: 0.1616
Epoch 16/60
29510/29510 [==============================] - 27s 906us/step - loss: 0.0198 - mean_absolute_error: 0.1507 - val_loss: 0.0166 - val_mean_absolute_error: 0.1260
Epoch 17/60
29510/29510 [==============================] - 27s 903us/step - loss: 0.0187 - mean_absolute_error: 0.1470 - val_loss: 0.0179 - val_mean_absolute_error: 0.1328
Epoch 18/60
29510/29510 [==============================] - 26s 897us/step - loss: 0.0186 - mean_absolute_error: 0.1470 - val_loss: 0.0183 - val_mean_absolute_error: 0.1343
Epoch 19/60
29510/29510 [==============================] - 26s 896us/step - loss: 0.0186 - mean_absolute_error: 0.1464 - val_loss: 0.0173 - val_mean_absolute_error: 0.1339
Epoch 20/60
29510/29510 [==============================] - 27s 898us/step - loss: 0.0180 - mean_absolute_error: 0.1439 - val_loss: 0.0201 - val_mean_absolute_error: 0.1420
Epoch 21/60
29510/29510 [==============================] - 27s 902us/step - loss: 0.0182 - mean_absolute_error: 0.1454 - val_loss: 0.0162 - val_mean_absolute_error: 0.1290
Epoch 22/60
29510/29510 [==============================] - 27s 898us/step - loss: 0.0182 - mean_absolute_error: 0.1456 - val_loss: 0.0168 - val_mean_absolute_error: 0.1298
Epoch 23/60
29510/29510 [==============================] - 27s 901us/step - loss: 0.0178 - mean_absolute_error: 0.1434 - val_loss: 0.0172 - val_mean_absolute_error: 0.1276
Epoch 24/60
29510/29510 [==============================] - 27s 901us/step - loss: 0.0176 - mean_absolute_error: 0.1430 - val_loss: 0.0172 - val_mean_absolute_error: 0.1290
Epoch 25/60
29510/29510 [==============================] - 27s 901us/step - loss: 0.0178 - mean_absolute_error: 0.1437 - val_loss: 0.0171 - val_mean_absolute_error: 0.1237
Epoch 26/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0173 - mean_absolute_error: 0.1417 - val_loss: 0.0160 - val_mean_absolute_error: 0.1268
Epoch 27/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0171 - mean_absolute_error: 0.1407 - val_loss: 0.0155 - val_mean_absolute_error: 0.1203
Epoch 28/60
29510/29510 [==============================] - 27s 905us/step - loss: 0.0168 - mean_absolute_error: 0.1395 - val_loss: 0.0212 - val_mean_absolute_error: 0.1541
Epoch 29/60
29510/29510 [==============================] - 27s 899us/step - loss: 0.0166 - mean_absolute_error: 0.1389 - val_loss: 0.0156 - val_mean_absolute_error: 0.1217
Epoch 30/60
29510/29510 [==============================] - 27s 902us/step - loss: 0.0161 - mean_absolute_error: 0.1365 - val_loss: 0.0169 - val_mean_absolute_error: 0.1275
Epoch 31/60
29510/29510 [==============================] - 27s 902us/step - loss: 0.0161 - mean_absolute_error: 0.1365 - val_loss: 0.0184 - val_mean_absolute_error: 0.1347
Epoch 32/60
29510/29510 [==============================] - 27s 903us/step - loss: 0.0162 - mean_absolute_error: 0.1367 - val_loss: 0.0161 - val_mean_absolute_error: 0.1236
Epoch 33/60
29510/29510 [==============================] - 27s 901us/step - loss: 0.0160 - mean_absolute_error: 0.1358 - val_loss: 0.0177 - val_mean_absolute_error: 0.1310
Epoch 34/60
29510/29510 [==============================] - 27s 908us/step - loss: 0.0159 - mean_absolute_error: 0.1354 - val_loss: 0.0213 - val_mean_absolute_error: 0.1440
Epoch 35/60
29510/29510 [==============================] - 27s 907us/step - loss: 0.0156 - mean_absolute_error: 0.1347 - val_loss: 0.0172 - val_mean_absolute_error: 0.1265
Epoch 36/60
29510/29510 [==============================] - 27s 904us/step - loss: 0.0111 - mean_absolute_error: 0.1117 - val_loss: 0.0170 - val_mean_absolute_error: 0.1276
Epoch 37/60
29510/29510 [==============================] - 27s 904us/step - loss: 0.0105 - mean_absolute_error: 0.1087 - val_loss: 0.0158 - val_mean_absolute_error: 0.1217
Epoch 38/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0103 - mean_absolute_error: 0.1069 - val_loss: 0.0165 - val_mean_absolute_error: 0.1239
Epoch 39/60
29510/29510 [==============================] - 27s 902us/step - loss: 0.0101 - mean_absolute_error: 0.1061 - val_loss: 0.0169 - val_mean_absolute_error: 0.1264
Epoch 40/60
29510/29510 [==============================] - 27s 901us/step - loss: 0.0100 - mean_absolute_error: 0.1059 - val_loss: 0.0191 - val_mean_absolute_error: 0.1318
Epoch 41/60
29510/29510 [==============================] - 27s 906us/step - loss: 0.0100 - mean_absolute_error: 0.1057 - val_loss: 0.0176 - val_mean_absolute_error: 0.1265
Epoch 42/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0099 - mean_absolute_error: 0.1050 - val_loss: 0.0180 - val_mean_absolute_error: 0.1285
Epoch 43/60
29510/29510 [==============================] - 27s 899us/step - loss: 0.0099 - mean_absolute_error: 0.1051 - val_loss: 0.0170 - val_mean_absolute_error: 0.1253
Epoch 44/60
29510/29510 [==============================] - 27s 906us/step - loss: 0.0097 - mean_absolute_error: 0.1045 - val_loss: 0.0183 - val_mean_absolute_error: 0.1304
Epoch 45/60
29510/29510 [==============================] - 27s 902us/step - loss: 0.0096 - mean_absolute_error: 0.1037 - val_loss: 0.0186 - val_mean_absolute_error: 0.1290
Epoch 46/60
29510/29510 [==============================] - 27s 906us/step - loss: 0.0091 - mean_absolute_error: 0.1004 - val_loss: 0.0175 - val_mean_absolute_error: 0.1260
Epoch 47/60
29510/29510 [==============================] - 27s 904us/step - loss: 0.0089 - mean_absolute_error: 0.0994 - val_loss: 0.0184 - val_mean_absolute_error: 0.1272
Epoch 48/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0089 - mean_absolute_error: 0.0996 - val_loss: 0.0185 - val_mean_absolute_error: 0.1276
Epoch 49/60
29510/29510 [==============================] - 27s 902us/step - loss: 0.0089 - mean_absolute_error: 0.0991 - val_loss: 0.0194 - val_mean_absolute_error: 0.1311
Epoch 50/60
29510/29510 [==============================] - 27s 906us/step - loss: 0.0087 - mean_absolute_error: 0.0981 - val_loss: 0.0183 - val_mean_absolute_error: 0.1291
Epoch 51/60
29510/29510 [==============================] - 27s 901us/step - loss: 0.0089 - mean_absolute_error: 0.0995 - val_loss: 0.0186 - val_mean_absolute_error: 0.1282
Epoch 52/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0087 - mean_absolute_error: 0.0985 - val_loss: 0.0182 - val_mean_absolute_error: 0.1272
Epoch 53/60
29510/29510 [==============================] - 27s 902us/step - loss: 0.0088 - mean_absolute_error: 0.0991 - val_loss: 0.0180 - val_mean_absolute_error: 0.1274
Epoch 54/60
29510/29510 [==============================] - 27s 904us/step - loss: 0.0088 - mean_absolute_error: 0.0987 - val_loss: 0.0186 - val_mean_absolute_error: 0.1285
Epoch 55/60
29510/29510 [==============================] - 27s 902us/step - loss: 0.0086 - mean_absolute_error: 0.0976 - val_loss: 0.0190 - val_mean_absolute_error: 0.1296
Epoch 56/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0082 - mean_absolute_error: 0.0954 - val_loss: 0.0186 - val_mean_absolute_error: 0.1284
Epoch 57/60
29510/29510 [==============================] - 26s 895us/step - loss: 0.0082 - mean_absolute_error: 0.0952 - val_loss: 0.0183 - val_mean_absolute_error: 0.1279
Epoch 58/60
29510/29510 [==============================] - 27s 898us/step - loss: 0.0081 - mean_absolute_error: 0.0948 - val_loss: 0.0183 - val_mean_absolute_error: 0.1277
Epoch 59/60
29510/29510 [==============================] - 27s 900us/step - loss: 0.0082 - mean_absolute_error: 0.0950 - val_loss: 0.0183 - val_mean_absolute_error: 0.1277
Epoch 60/60
29510/29510 [==============================] - 27s 903us/step - loss: 0.0081 - mean_absolute_error: 0.0946 - val_loss: 0.0182 - val_mean_absolute_error: 0.1274
train MAE:  0.08129364
train RMSE:  0.1144633197475331
test MAE:  0.12735954
test RMSE:  0.20097746297414
