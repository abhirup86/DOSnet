Using TensorFlow backend.
2020-07-03 16:28:40.676493: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-03 16:28:40.688582: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2299930000 Hz
2020-07-03 16:28:40.691716: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2aacb0000b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-03 16:28:40.691730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-03 16:28:40.717568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-03 16:28:40.745461: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-07-03 16:28:40.745493: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nid00027): /proc/driver/nvidia/version does not exist
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 8216990913968568972
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 1130056764578423128
physical_device_desc: "device: XLA_CPU device"
]
2020-07-03 16:30:11.487396: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.
readenergyb_test3_all2p_backup4_backup3_branch_production_transfer.py:116: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("de...)`
  model=Model(input=[input1, input2, input3, input4], output=out)
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_3 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
model_1 (Model)                 (None, 4, 150)       155200      input_3[0][0]
                                                                 input_4[0][0]
                                                                 input_5[0][0]
__________________________________________________________________________________________________
model_3 (Model)                 (None, 4, 150)       155200      input_6[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 4, 600)       0           model_1[1][0]
                                                                 model_1[2][0]
                                                                 model_1[3][0]
                                                                 model_3[1][0]
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2400)         0           concatenate_4[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2400)         0           flatten_1[0][0]
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 200)          480200      dropout_1[0][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1000)         201000      dense_1[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1000)         1001000     dense_2[0][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            1001        dense_3[0][0]
==================================================================================================
Total params: 1,993,601
Trainable params: 1,993,401
Non-trainable params: 200
__________________________________________________________________________________________________
Train on 31323 samples, validate on 4615 samples
Epoch 1/60
  256/31323 [..............................] - ETA: 2:34 - loss: 1.2157 - mean_absolute_error: 1.77282020-07-03 16:30:16.132314: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: logs/1593819011.48732/train/plugins/profile/2020_07_03_16_30_16
2020-07-03 16:30:16.140566: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to logs/1593819011.48732/train/plugins/profile/2020_07_03_16_30_16/nid00027.trace.json.gz
2020-07-03 16:30:16.145591: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.234 ms

2020-07-03 16:30:16.160503: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: logs/1593819011.48732/train/plugins/profile/2020_07_03_16_30_16Dumped tool data for overview_page.pb to logs/1593819011.48732/train/plugins/profile/2020_07_03_16_30_16/nid00027.overview_page.pb
Dumped tool data for input_pipeline.pb to logs/1593819011.48732/train/plugins/profile/2020_07_03_16_30_16/nid00027.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to logs/1593819011.48732/train/plugins/profile/2020_07_03_16_30_16/nid00027.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to logs/1593819011.48732/train/plugins/profile/2020_07_03_16_30_16/nid00027.kernel_stats.pb
31323/31323 [==============================] - 29s 925us/step - loss: 0.1842 - mean_absolute_error: 0.4847 - val_loss: 0.0709 - val_mean_absolute_error: 0.2680
Epoch 2/60
31323/31323 [==============================] - 28s 882us/step - loss: 0.0693 - mean_absolute_error: 0.2922 - val_loss: 0.0227 - val_mean_absolute_error: 0.1554
Epoch 3/60
31323/31323 [==============================] - 28s 882us/step - loss: 0.0573 - mean_absolute_error: 0.2648 - val_loss: 0.0203 - val_mean_absolute_error: 0.1426
Epoch 4/60
31323/31323 [==============================] - 28s 881us/step - loss: 0.0488 - mean_absolute_error: 0.2428 - val_loss: 0.0170 - val_mean_absolute_error: 0.1226
Epoch 5/60
31323/31323 [==============================] - 27s 878us/step - loss: 0.0427 - mean_absolute_error: 0.2266 - val_loss: 0.0185 - val_mean_absolute_error: 0.1331
Epoch 6/60
31323/31323 [==============================] - 28s 884us/step - loss: 0.0395 - mean_absolute_error: 0.2166 - val_loss: 0.0139 - val_mean_absolute_error: 0.1110
Epoch 7/60
31323/31323 [==============================] - 28s 881us/step - loss: 0.0376 - mean_absolute_error: 0.2117 - val_loss: 0.0156 - val_mean_absolute_error: 0.1200
Epoch 8/60
31323/31323 [==============================] - 27s 877us/step - loss: 0.0347 - mean_absolute_error: 0.2032 - val_loss: 0.0166 - val_mean_absolute_error: 0.1247
Epoch 9/60
31323/31323 [==============================] - 28s 879us/step - loss: 0.0334 - mean_absolute_error: 0.1988 - val_loss: 0.0210 - val_mean_absolute_error: 0.1585
Epoch 10/60
31323/31323 [==============================] - 27s 878us/step - loss: 0.0302 - mean_absolute_error: 0.1891 - val_loss: 0.0137 - val_mean_absolute_error: 0.1150
Epoch 11/60
31323/31323 [==============================] - 28s 882us/step - loss: 0.0301 - mean_absolute_error: 0.1884 - val_loss: 0.0159 - val_mean_absolute_error: 0.1307
Epoch 12/60
31323/31323 [==============================] - 28s 883us/step - loss: 0.0290 - mean_absolute_error: 0.1839 - val_loss: 0.0129 - val_mean_absolute_error: 0.1090
Epoch 13/60
31323/31323 [==============================] - 28s 882us/step - loss: 0.0292 - mean_absolute_error: 0.1854 - val_loss: 0.0116 - val_mean_absolute_error: 0.1040
Epoch 14/60
31323/31323 [==============================] - 28s 881us/step - loss: 0.0275 - mean_absolute_error: 0.1792 - val_loss: 0.0120 - val_mean_absolute_error: 0.1042
Epoch 15/60
31323/31323 [==============================] - 28s 879us/step - loss: 0.0259 - mean_absolute_error: 0.1744 - val_loss: 0.0119 - val_mean_absolute_error: 0.1071
Epoch 16/60
31323/31323 [==============================] - 28s 881us/step - loss: 0.0192 - mean_absolute_error: 0.1479 - val_loss: 0.0098 - val_mean_absolute_error: 0.0941
Epoch 17/60
31323/31323 [==============================] - 27s 876us/step - loss: 0.0184 - mean_absolute_error: 0.1447 - val_loss: 0.0103 - val_mean_absolute_error: 0.0996
Epoch 18/60
31323/31323 [==============================] - 27s 876us/step - loss: 0.0182 - mean_absolute_error: 0.1439 - val_loss: 0.0107 - val_mean_absolute_error: 0.1024
Epoch 19/60
31323/31323 [==============================] - 27s 874us/step - loss: 0.0175 - mean_absolute_error: 0.1414 - val_loss: 0.0094 - val_mean_absolute_error: 0.0945
Epoch 20/60
31323/31323 [==============================] - 27s 877us/step - loss: 0.0180 - mean_absolute_error: 0.1435 - val_loss: 0.0097 - val_mean_absolute_error: 0.0998
Epoch 21/60
31323/31323 [==============================] - 27s 872us/step - loss: 0.0175 - mean_absolute_error: 0.1412 - val_loss: 0.0110 - val_mean_absolute_error: 0.1116
Epoch 22/60
31323/31323 [==============================] - 27s 876us/step - loss: 0.0179 - mean_absolute_error: 0.1436 - val_loss: 0.0108 - val_mean_absolute_error: 0.1056
Epoch 23/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0173 - mean_absolute_error: 0.1417 - val_loss: 0.0088 - val_mean_absolute_error: 0.0924
Epoch 24/60
31323/31323 [==============================] - 27s 872us/step - loss: 0.0171 - mean_absolute_error: 0.1399 - val_loss: 0.0097 - val_mean_absolute_error: 0.0984
Epoch 25/60
31323/31323 [==============================] - 27s 874us/step - loss: 0.0169 - mean_absolute_error: 0.1397 - val_loss: 0.0088 - val_mean_absolute_error: 0.0911
Epoch 26/60
31323/31323 [==============================] - 28s 878us/step - loss: 0.0167 - mean_absolute_error: 0.1386 - val_loss: 0.0097 - val_mean_absolute_error: 0.0989
Epoch 27/60
31323/31323 [==============================] - 27s 874us/step - loss: 0.0165 - mean_absolute_error: 0.1378 - val_loss: 0.0084 - val_mean_absolute_error: 0.0941
Epoch 28/60
31323/31323 [==============================] - 27s 872us/step - loss: 0.0165 - mean_absolute_error: 0.1379 - val_loss: 0.0082 - val_mean_absolute_error: 0.0895
Epoch 29/60
31323/31323 [==============================] - 28s 879us/step - loss: 0.0163 - mean_absolute_error: 0.1370 - val_loss: 0.0080 - val_mean_absolute_error: 0.0890
Epoch 30/60
31323/31323 [==============================] - 27s 873us/step - loss: 0.0157 - mean_absolute_error: 0.1339 - val_loss: 0.0094 - val_mean_absolute_error: 0.0984
Epoch 31/60
31323/31323 [==============================] - 27s 873us/step - loss: 0.0152 - mean_absolute_error: 0.1325 - val_loss: 0.0088 - val_mean_absolute_error: 0.0932
Epoch 32/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0153 - mean_absolute_error: 0.1328 - val_loss: 0.0082 - val_mean_absolute_error: 0.0900
Epoch 33/60
31323/31323 [==============================] - 27s 874us/step - loss: 0.0151 - mean_absolute_error: 0.1314 - val_loss: 0.0095 - val_mean_absolute_error: 0.0956
Epoch 34/60
31323/31323 [==============================] - 27s 877us/step - loss: 0.0152 - mean_absolute_error: 0.1318 - val_loss: 0.0082 - val_mean_absolute_error: 0.0883
Epoch 35/60
31323/31323 [==============================] - 27s 876us/step - loss: 0.0143 - mean_absolute_error: 0.1284 - val_loss: 0.0085 - val_mean_absolute_error: 0.0917
Epoch 36/60
31323/31323 [==============================] - 27s 877us/step - loss: 0.0107 - mean_absolute_error: 0.1091 - val_loss: 0.0073 - val_mean_absolute_error: 0.0839
Epoch 37/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0100 - mean_absolute_error: 0.1055 - val_loss: 0.0071 - val_mean_absolute_error: 0.0821
Epoch 38/60
31323/31323 [==============================] - 27s 877us/step - loss: 0.0097 - mean_absolute_error: 0.1042 - val_loss: 0.0069 - val_mean_absolute_error: 0.0818
Epoch 39/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0098 - mean_absolute_error: 0.1046 - val_loss: 0.0071 - val_mean_absolute_error: 0.0818
Epoch 40/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0097 - mean_absolute_error: 0.1034 - val_loss: 0.0071 - val_mean_absolute_error: 0.0813
Epoch 41/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0094 - mean_absolute_error: 0.1024 - val_loss: 0.0076 - val_mean_absolute_error: 0.0851
Epoch 42/60
31323/31323 [==============================] - 27s 871us/step - loss: 0.0095 - mean_absolute_error: 0.1022 - val_loss: 0.0072 - val_mean_absolute_error: 0.0824
Epoch 43/60
31323/31323 [==============================] - 27s 871us/step - loss: 0.0094 - mean_absolute_error: 0.1023 - val_loss: 0.0074 - val_mean_absolute_error: 0.0831
Epoch 44/60
31323/31323 [==============================] - 27s 876us/step - loss: 0.0093 - mean_absolute_error: 0.1014 - val_loss: 0.0074 - val_mean_absolute_error: 0.0822
Epoch 45/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0091 - mean_absolute_error: 0.1006 - val_loss: 0.0070 - val_mean_absolute_error: 0.0815
Epoch 46/60
31323/31323 [==============================] - 27s 874us/step - loss: 0.0086 - mean_absolute_error: 0.0975 - val_loss: 0.0070 - val_mean_absolute_error: 0.0811
Epoch 47/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0086 - mean_absolute_error: 0.0973 - val_loss: 0.0069 - val_mean_absolute_error: 0.0805
Epoch 48/60
31323/31323 [==============================] - 27s 873us/step - loss: 0.0086 - mean_absolute_error: 0.0975 - val_loss: 0.0070 - val_mean_absolute_error: 0.0811
Epoch 49/60
31323/31323 [==============================] - 27s 877us/step - loss: 0.0086 - mean_absolute_error: 0.0969 - val_loss: 0.0071 - val_mean_absolute_error: 0.0818
Epoch 50/60
31323/31323 [==============================] - 27s 874us/step - loss: 0.0084 - mean_absolute_error: 0.0963 - val_loss: 0.0070 - val_mean_absolute_error: 0.0809
Epoch 51/60
31323/31323 [==============================] - 27s 872us/step - loss: 0.0084 - mean_absolute_error: 0.0963 - val_loss: 0.0070 - val_mean_absolute_error: 0.0809
Epoch 52/60
31323/31323 [==============================] - 27s 873us/step - loss: 0.0085 - mean_absolute_error: 0.0970 - val_loss: 0.0071 - val_mean_absolute_error: 0.0816
Epoch 53/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0084 - mean_absolute_error: 0.0965 - val_loss: 0.0072 - val_mean_absolute_error: 0.0816
Epoch 54/60
31323/31323 [==============================] - 28s 878us/step - loss: 0.0083 - mean_absolute_error: 0.0960 - val_loss: 0.0073 - val_mean_absolute_error: 0.0814
Epoch 55/60
31323/31323 [==============================] - 27s 871us/step - loss: 0.0083 - mean_absolute_error: 0.0958 - val_loss: 0.0072 - val_mean_absolute_error: 0.0815
Epoch 56/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0079 - mean_absolute_error: 0.0928 - val_loss: 0.0070 - val_mean_absolute_error: 0.0802
Epoch 57/60
31323/31323 [==============================] - 27s 876us/step - loss: 0.0078 - mean_absolute_error: 0.0924 - val_loss: 0.0069 - val_mean_absolute_error: 0.0800
Epoch 58/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0078 - mean_absolute_error: 0.0926 - val_loss: 0.0069 - val_mean_absolute_error: 0.0798
Epoch 59/60
31323/31323 [==============================] - 28s 880us/step - loss: 0.0078 - mean_absolute_error: 0.0927 - val_loss: 0.0070 - val_mean_absolute_error: 0.0802
Epoch 60/60
31323/31323 [==============================] - 27s 875us/step - loss: 0.0078 - mean_absolute_error: 0.0923 - val_loss: 0.0070 - val_mean_absolute_error: 0.0802
train MAE:  0.0786609
train RMSE:  0.11162958822026364
test MAE:  0.080232695
test RMSE:  0.12058304180478223
