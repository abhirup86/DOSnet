37247
['index: ', 4, 'filename: ', '1_screen/4/DOS9', 'reaction: ', '0.5H2(g) + * -> H*', 'site: ', '{"H": "bridge|A_A|B"}', 'surface: ', ['Pt', 'Pt', 'Pt', 'Ti', 'Pt', 'Pt', 'Pt', 'Ti', 'Pt', 'Pt', 'Pt', 'Ti']]
35938
[6975, 5342, 23621]
float32
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

/global/cscratch1/sd/vfung/1_screen_copy/readenergyb_test3_all2p_backup4_backup3_branch.py:190: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("de...)`
  model=Model(input=[input1, input2, input3, input4], output=out)
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_3 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 2000, 9)      0
__________________________________________________________________________________________________
model_1 (Model)                 (None, 4, 150)       155200      input_3[0][0]
                                                                 input_4[0][0]
                                                                 input_5[0][0]
__________________________________________________________________________________________________
model_3 (Model)                 (None, 4, 150)       155200      input_6[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 4, 600)       0           model_1[1][0]
                                                                 model_1[2][0]
                                                                 model_1[3][0]
                                                                 model_3[1][0]
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2400)         0           concatenate_4[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2400)         0           flatten_1[0][0]
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 200)          480200      dropout_1[0][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1000)         201000      dense_1[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1000)         1001000     dense_2[0][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            1001        dense_3[0][0]
==================================================================================================
Total params: 1,993,601
Trainable params: 1,993,401
Non-trainable params: 200
__________________________________________________________________________________________________
2020-06-15 16:45:17.381727: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Train on 988 samples, validate on 34950 samples
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:198: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Epoch 1/60
988/988 [==============================] - 66s 67ms/step - loss: 0.5230 - mean_absolute_error: 0.9692 - val_loss: 0.6846 - val_mean_absolute_error: 1.1661
WARNING:tensorflow:From /global/homes/v/vfung/.local/cori/3.6-anaconda-5.2/lib/python3.6/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

Epoch 2/60
988/988 [==============================] - 65s 66ms/step - loss: 0.2547 - mean_absolute_error: 0.6062 - val_loss: 0.6983 - val_mean_absolute_error: 1.1780
Epoch 3/60
988/988 [==============================] - 65s 66ms/step - loss: 0.2108 - mean_absolute_error: 0.5455 - val_loss: 0.5900 - val_mean_absolute_error: 1.0266
Epoch 4/60
988/988 [==============================] - 65s 65ms/step - loss: 0.1939 - mean_absolute_error: 0.5197 - val_loss: 0.3130 - val_mean_absolute_error: 0.6931
Epoch 5/60
988/988 [==============================] - 65s 65ms/step - loss: 0.1895 - mean_absolute_error: 0.5049 - val_loss: 0.2689 - val_mean_absolute_error: 0.6204
Epoch 6/60
988/988 [==============================] - 65s 66ms/step - loss: 0.1444 - mean_absolute_error: 0.4324 - val_loss: 0.2450 - val_mean_absolute_error: 0.5897
Epoch 7/60
988/988 [==============================] - 64s 65ms/step - loss: 0.1434 - mean_absolute_error: 0.4311 - val_loss: 0.1604 - val_mean_absolute_error: 0.4595
Epoch 8/60
988/988 [==============================] - 65s 65ms/step - loss: 0.1304 - mean_absolute_error: 0.4163 - val_loss: 0.1946 - val_mean_absolute_error: 0.5238
Epoch 9/60
988/988 [==============================] - 65s 65ms/step - loss: 0.1347 - mean_absolute_error: 0.4200 - val_loss: 0.2165 - val_mean_absolute_error: 0.5458
Epoch 10/60
988/988 [==============================] - 64s 65ms/step - loss: 0.1606 - mean_absolute_error: 0.4652 - val_loss: 0.1346 - val_mean_absolute_error: 0.4129
Epoch 11/60
988/988 [==============================] - 64s 65ms/step - loss: 0.1118 - mean_absolute_error: 0.3793 - val_loss: 0.1446 - val_mean_absolute_error: 0.4194
Epoch 12/60
988/988 [==============================] - 64s 65ms/step - loss: 0.1207 - mean_absolute_error: 0.3958 - val_loss: 0.1550 - val_mean_absolute_error: 0.4364
Epoch 13/60
988/988 [==============================] - 65s 66ms/step - loss: 0.1090 - mean_absolute_error: 0.3709 - val_loss: 0.1482 - val_mean_absolute_error: 0.4330
Epoch 14/60
988/988 [==============================] - 65s 65ms/step - loss: 0.1110 - mean_absolute_error: 0.3819 - val_loss: 0.1071 - val_mean_absolute_error: 0.3673
Epoch 15/60
988/988 [==============================] - 65s 66ms/step - loss: 0.0902 - mean_absolute_error: 0.3322 - val_loss: 0.1257 - val_mean_absolute_error: 0.3946
Epoch 16/60
988/988 [==============================] - 65s 66ms/step - loss: 0.0783 - mean_absolute_error: 0.3109 - val_loss: 0.0918 - val_mean_absolute_error: 0.3286
Epoch 17/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0679 - mean_absolute_error: 0.2883 - val_loss: 0.0946 - val_mean_absolute_error: 0.3330
Epoch 18/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0580 - mean_absolute_error: 0.2655 - val_loss: 0.1016 - val_mean_absolute_error: 0.3465
Epoch 19/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0693 - mean_absolute_error: 0.2916 - val_loss: 0.1249 - val_mean_absolute_error: 0.3841
Epoch 20/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0632 - mean_absolute_error: 0.2786 - val_loss: 0.0900 - val_mean_absolute_error: 0.3260
Epoch 21/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0537 - mean_absolute_error: 0.2538 - val_loss: 0.0866 - val_mean_absolute_error: 0.3170
Epoch 22/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0526 - mean_absolute_error: 0.2489 - val_loss: 0.0979 - val_mean_absolute_error: 0.3450
Epoch 23/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0640 - mean_absolute_error: 0.2814 - val_loss: 0.0891 - val_mean_absolute_error: 0.3263
Epoch 24/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0586 - mean_absolute_error: 0.2675 - val_loss: 0.0906 - val_mean_absolute_error: 0.3253
Epoch 25/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0523 - mean_absolute_error: 0.2554 - val_loss: 0.0838 - val_mean_absolute_error: 0.3128
Epoch 26/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0503 - mean_absolute_error: 0.2462 - val_loss: 0.0889 - val_mean_absolute_error: 0.3222
Epoch 27/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0577 - mean_absolute_error: 0.2706 - val_loss: 0.0802 - val_mean_absolute_error: 0.3005
Epoch 28/60
988/988 [==============================] - 65s 66ms/step - loss: 0.0476 - mean_absolute_error: 0.2420 - val_loss: 0.0827 - val_mean_absolute_error: 0.3038
Epoch 29/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0460 - mean_absolute_error: 0.2374 - val_loss: 0.1024 - val_mean_absolute_error: 0.3492
Epoch 30/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0433 - mean_absolute_error: 0.2295 - val_loss: 0.0769 - val_mean_absolute_error: 0.2956
Epoch 31/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0447 - mean_absolute_error: 0.2355 - val_loss: 0.0839 - val_mean_absolute_error: 0.3031
Epoch 32/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0479 - mean_absolute_error: 0.2368 - val_loss: 0.0856 - val_mean_absolute_error: 0.3072
Epoch 33/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0451 - mean_absolute_error: 0.2324 - val_loss: 0.0850 - val_mean_absolute_error: 0.3166
Epoch 34/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0464 - mean_absolute_error: 0.2414 - val_loss: 0.0992 - val_mean_absolute_error: 0.3412
Epoch 35/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0412 - mean_absolute_error: 0.2229 - val_loss: 0.0866 - val_mean_absolute_error: 0.3130
Epoch 36/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0275 - mean_absolute_error: 0.1832 - val_loss: 0.0736 - val_mean_absolute_error: 0.2830
Epoch 37/60
988/988 [==============================] - 65s 66ms/step - loss: 0.0247 - mean_absolute_error: 0.1721 - val_loss: 0.0749 - val_mean_absolute_error: 0.2855
Epoch 38/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0222 - mean_absolute_error: 0.1628 - val_loss: 0.0721 - val_mean_absolute_error: 0.2824
Epoch 39/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0225 - mean_absolute_error: 0.1616 - val_loss: 0.0736 - val_mean_absolute_error: 0.2829
Epoch 40/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0230 - mean_absolute_error: 0.1633 - val_loss: 0.0707 - val_mean_absolute_error: 0.2776
Epoch 41/60
988/988 [==============================] - 65s 66ms/step - loss: 0.0219 - mean_absolute_error: 0.1621 - val_loss: 0.0714 - val_mean_absolute_error: 0.2795
Epoch 42/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0200 - mean_absolute_error: 0.1545 - val_loss: 0.0711 - val_mean_absolute_error: 0.2770
Epoch 43/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0208 - mean_absolute_error: 0.1565 - val_loss: 0.0708 - val_mean_absolute_error: 0.2773
Epoch 44/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0185 - mean_absolute_error: 0.1458 - val_loss: 0.0752 - val_mean_absolute_error: 0.2851
Epoch 45/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0178 - mean_absolute_error: 0.1435 - val_loss: 0.0741 - val_mean_absolute_error: 0.2862
Epoch 46/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0185 - mean_absolute_error: 0.1485 - val_loss: 0.0709 - val_mean_absolute_error: 0.2777
Epoch 47/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0175 - mean_absolute_error: 0.1442 - val_loss: 0.0708 - val_mean_absolute_error: 0.2771
Epoch 48/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0181 - mean_absolute_error: 0.1472 - val_loss: 0.0704 - val_mean_absolute_error: 0.2766
Epoch 49/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0177 - mean_absolute_error: 0.1420 - val_loss: 0.0698 - val_mean_absolute_error: 0.2743
Epoch 50/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0165 - mean_absolute_error: 0.1405 - val_loss: 0.0719 - val_mean_absolute_error: 0.2790
Epoch 51/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0178 - mean_absolute_error: 0.1444 - val_loss: 0.0693 - val_mean_absolute_error: 0.2746
Epoch 52/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0163 - mean_absolute_error: 0.1404 - val_loss: 0.0693 - val_mean_absolute_error: 0.2744
Epoch 53/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0165 - mean_absolute_error: 0.1384 - val_loss: 0.0704 - val_mean_absolute_error: 0.2756
Epoch 54/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0174 - mean_absolute_error: 0.1463 - val_loss: 0.0693 - val_mean_absolute_error: 0.2742
Epoch 55/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0170 - mean_absolute_error: 0.1432 - val_loss: 0.0686 - val_mean_absolute_error: 0.2723
Epoch 56/60
988/988 [==============================] - 65s 66ms/step - loss: 0.0159 - mean_absolute_error: 0.1379 - val_loss: 0.0692 - val_mean_absolute_error: 0.2730
Epoch 57/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0158 - mean_absolute_error: 0.1379 - val_loss: 0.0691 - val_mean_absolute_error: 0.2726
Epoch 58/60
988/988 [==============================] - 64s 65ms/step - loss: 0.0138 - mean_absolute_error: 0.1285 - val_loss: 0.0687 - val_mean_absolute_error: 0.2721
Epoch 59/60
988/988 [==============================] - 65s 65ms/step - loss: 0.0168 - mean_absolute_error: 0.1423 - val_loss: 0.0689 - val_mean_absolute_error: 0.2726
Epoch 60/60
988/988 [==============================] - 65s 66ms/step - loss: 0.0142 - mean_absolute_error: 0.1290 - val_loss: 0.0691 - val_mean_absolute_error: 0.2728
 train MAE:  0.09409374
 train RMSE:  0.1273969960205138
 test MAE:  0.2727697
 test RMSE:  0.4011850431039877
